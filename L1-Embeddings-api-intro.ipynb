{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "207942ee-1cad-4ff4-a64a-90aebc10d040",
   "metadata": {},
   "source": [
    "# Getting Started With Text Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed132594-2b03-449b-87e2-2529d60aa05a",
   "metadata": {},
   "source": [
    "#### Project environment setup\n",
    "\n",
    "- Load credentials and relevant Python Libraries\n",
    "- If you were running this notebook locally, you would first install Vertex AI.  In this classroom, this is already installed.\n",
    "```Python\n",
    "!pip install google-cloud-aiplatform\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2931ae6b-23c1-4d02-a724-1bc0b1b9a820",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from utils import authenticate\n",
    "credentials, PROJECT_ID = authenticate() # Get credentials and project ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cfcd44-8eba-4eee-b7b4-a7be3c876685",
   "metadata": {},
   "source": [
    "#### Enter project details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb9c9a86-f9bd-45a6-93c2-f6dbf7d32b12",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLAI_PROJECT\n"
     ]
    }
   ],
   "source": [
    "print(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d411edf-7fe6-4160-9ecb-6f5e05161951",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9223fa5-1cd8-42a9-a967-9f2c848727ee",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# Import and initialize the Vertex AI Python SDK\n",
    "\n",
    "import vertexai\n",
    "vertexai.init(project = PROJECT_ID, \n",
    "              location = REGION, \n",
    "              credentials = credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e448c9f-8311-420b-b408-a1fb712bbff4",
   "metadata": {},
   "source": [
    "#### Use the embeddings model\n",
    "- Import and load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "681bfe86-6880-4afa-bdd6-77a8dfbc5f21",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextEmbeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa62b23a-b423-4651-88f1-b00509900be3",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "embedding_model = TextEmbeddingModel.from_pretrained(\n",
    "    \"textembedding-gecko@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2289d4-882f-4336-a720-75e80cac6900",
   "metadata": {},
   "source": [
    "- Generate a word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f05aea17-cb72-4c7f-9da2-df0ee954e663",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 1 column 5 (char 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 5 (char 4)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43membedding_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlife\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/vertexai/language_models/_language_models.py:508\u001b[0m, in \u001b[0;36mTextEmbeddingModel.get_embeddings\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextEmbedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# instances = [{\"content\": str(text)} for text in texts]\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m#     for prediction in prediction_response.predictions\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m     prediction_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dlai_custom_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    510\u001b[0m         TextEmbedding(\n\u001b[1;32m    511\u001b[0m             values\u001b[38;5;241m=\u001b[39mprediction\n\u001b[1;32m    512\u001b[0m         )\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m prediction \u001b[38;5;129;01min\u001b[39;00m prediction_response\n\u001b[1;32m    514\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/vertexai/language_models/_language_models.py:532\u001b[0m, in \u001b[0;36mTextEmbeddingModel._dlai_custom_api\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    527\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAPI_KEY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    530\u001b[0m }\n\u001b[1;32m    531\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, headers\u001b[38;5;241m=\u001b[39mheaders, data\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(payload))\n\u001b[0;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 5 (char 4)"
     ]
    }
   ],
   "source": [
    "embedding = embedding_model.get_embeddings(\n",
    "    [\"life\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a6bc7-455a-4783-93d5-fa491e82e828",
   "metadata": {},
   "source": [
    "- The returned object is a list with a single `TextEmbedding` object.\n",
    "- The `TextEmbedding.values` field stores the embeddings in a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea301db6-a439-4c0b-aae1-5e6ef943419c",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vector \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(vector)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(vector[:\u001b[38;5;241m10\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding' is not defined"
     ]
    }
   ],
   "source": [
    "vector = embedding[0].values\n",
    "print(f\"Length = {len(vector)}\")\n",
    "print(vector[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b803ae9-dd2e-421e-bc06-d6e7e0898b06",
   "metadata": {},
   "source": [
    "- Generate a sentence embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a4cd7-f89a-4931-ae16-519d1feb5197",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "embedding = embedding_model.get_embeddings(\n",
    "    [\"What is the meaning of life?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0182e-1744-4fbb-b240-2d193ec907d4",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "vector = embedding[0].values\n",
    "print(f\"Length = {len(vector)}\")\n",
    "print(vector[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7179f3de-e405-4c97-aaf5-055a99c464b6",
   "metadata": {},
   "source": [
    "#### Similarity\n",
    "\n",
    "- Calculate the similarity between two sentences as a number between 0 and 1.\n",
    "- Try out your own sentences and check if the similarity calculations match your intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b2520b-9687-4eed-be07-9ff75f1fcd74",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04483bf2-4d5d-4fd2-9aec-27711f2c780c",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "emb_1 = embedding_model.get_embeddings(\n",
    "    [\"What is the meaning of life?\"]) # 42!\n",
    "\n",
    "emb_2 = embedding_model.get_embeddings(\n",
    "    [\"How does one spend their time well on Earth?\"])\n",
    "\n",
    "emb_3 = embedding_model.get_embeddings(\n",
    "    [\"Would you like a salad?\"])\n",
    "\n",
    "vec_1 = [emb_1[0].values]\n",
    "vec_2 = [emb_2[0].values]\n",
    "vec_3 = [emb_3[0].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e70a55-21a4-4532-be59-1b9749d639b0",
   "metadata": {},
   "source": [
    "- Note: the reason we wrap the embeddings (a Python list) in another list is because the `cosine_similarity` function expects either a 2D numpy array or a list of lists.\n",
    "```Python\n",
    "vec_1 = [emb_1[0].values]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b370eaa-a3b7-44e4-90a2-6dc84e460122",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "print(cosine_similarity(vec_1,vec_2)) \n",
    "print(cosine_similarity(vec_2,vec_3))\n",
    "print(cosine_similarity(vec_1,vec_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b69f0-e64b-477d-9466-72ba1be05043",
   "metadata": {},
   "source": [
    "#### From word to sentence embeddings\n",
    "- One possible way to calculate sentence embeddings from word embeddings is to take the average of the word embeddings.\n",
    "- This ignores word order and context, so two sentences with different meanings, but the same set of words will end up with the same sentence embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88fff09-a268-4a29-a04b-7c84a588db80",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "in_1 = \"The kids play in the park.\"\n",
    "in_2 = \"The play was for kids in the park.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40437875-53db-4c88-8882-a2d6266d43d3",
   "metadata": {},
   "source": [
    "- Remove stop words like [\"the\", \"in\", \"for\", \"an\", \"is\"] and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab3a74-ec19-48cc-b5fb-1f0bd520b2c2",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "in_pp_1 = [\"kids\", \"play\", \"park\"]\n",
    "in_pp_2 = [\"play\", \"kids\", \"park\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2202a83-a704-41aa-ae2a-ba9ee2afd351",
   "metadata": {},
   "source": [
    "- Generate one embedding for each word.  So this is a list of three lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412df546-e2e2-4a90-9cd4-86b4887ab908",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "embeddings_1 = [emb.values for emb in embedding_model.get_embeddings(in_pp_1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac14b1-3d55-4227-9014-88447d5a08b8",
   "metadata": {},
   "source": [
    "- Use numpy to convert this list of lists into a 2D array of 3 rows and 768 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bcf45a-fb96-4838-a676-fbf52afc0b32",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "emb_array_1 = np.stack(embeddings_1)\n",
    "print(emb_array_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d20a4e-c56d-4a23-83ff-97d98e86cf32",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "embeddings_2 = [emb.values for emb in embedding_model.get_embeddings(in_pp_2)]\n",
    "emb_array_2 = np.stack(embeddings_2)\n",
    "print(emb_array_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83a56b-404d-4517-a666-c161f92ae48f",
   "metadata": {},
   "source": [
    "- Take the average embedding across the 3 word embeddings \n",
    "- You'll get a single embedding of length 768."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d9b65-a0ce-49eb-9627-b550053663c3",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "emb_1_mean = emb_array_1.mean(axis = 0) \n",
    "print(emb_1_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba79b5-ba81-4c7e-b1d8-642b428e16ec",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "emb_2_mean = emb_array_2.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe77e1-0b0c-407e-b179-862db2e2e454",
   "metadata": {},
   "source": [
    "- Check to see that taking an average of word embeddings results in two sentence embeddings that are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd51c8-cee8-46f1-b717-0a44ff8f1d1c",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "print(emb_1_mean[:4])\n",
    "print(emb_2_mean[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8014b28-ddfa-43e0-969b-5bd4ed0f6fdb",
   "metadata": {},
   "source": [
    "#### Get sentence embeddings from the model.\n",
    "- These sentence embeddings account for word order and context.\n",
    "- Verify that the sentence embeddings are not the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f69ff3c-dd02-45ae-b34c-a10f3d78614b",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "print(in_1)\n",
    "print(in_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dcfe77-013f-4cdc-a6c5-455c364b2507",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "embedding_1 = embedding_model.get_embeddings([in_1])\n",
    "embedding_2 = embedding_model.get_embeddings([in_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e998f-01b4-4d90-b509-cb03f26c106c",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "vector_1 = embedding_1[0].values\n",
    "print(vector_1[:4])\n",
    "vector_2 = embedding_2[0].values\n",
    "print(vector_2[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccfbb6f-c72b-4f5e-a86c-265bab07d9e1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
